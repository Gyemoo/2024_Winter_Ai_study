## 문제
다음과 같은 코드에서 나올 결과를 적고, 이렇게 나오는 이유를 설명하시오.


```python
from tensorflow.keras.preprocessing.text import Tokenizer
from keras.utils import to_categorical

text= "엔드 게임에서 아이언맨은 죽는다."

token = Tokenizer()
token.fit_on_texts([text])
x = token.texts_to_sequences([text])

word_size = len(token.word_index)+1
x = to_categorical(x, num_classes=word_size)

print(x)
```
<br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/><br/>

## 답
```python
[[[0. 1. 0. 0. 0.]
  [0. 0. 1. 0. 0.]
  [0. 0. 0. 1. 0.]
  [0. 0. 0. 0. 1.]]]
```
이유 : 텍스트 토큰화를 통해서 단어의 빈도 수를 잰 후 단어가 문장의 다른 요소와 어떤 관계를 가지고 있는지를 알아보는 방법인 원-핫 인코딩을 활용하였기 때문이다.
이 때 파이썬 배열의 인덱스는 0부터 시작하고, '엔드', '게임에서', '아이언맨은', '죽는다.'로 총 4가지의 단어가 있기에 다음가 같은 결과가 나온다.
