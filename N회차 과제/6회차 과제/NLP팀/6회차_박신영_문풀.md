## 1. 임시현 문제
'''python
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint # 여기

import pandas as pd
import numpy as np
import os # 여기
import tensorflow as tf
import matplotlib.pyplot as plt

seed=0
numpy.random.seed(seed)
tf.random.set_seed(3)

df_pre = pd.read_csv(' ', header=None)
df = df_pre.sample(frac=1)
dataset = df.values
X = dataset[:, 0:12]
Y = dataset[:, 12]

model = Sequential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

MODEL_DIR = './model/'
if not os.path.exists(MODEL_DIR):
  os.mkdir(MODEL_DIR)

modelpath = "./model/{epoch:02d}-{val_loss:.4f}.hdf5"

checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True) 

model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer])
'''

![image](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/128358741/c6d22ec5-fcce-4775-82f7-23b605db0d2b)
- 1번: 시그모이드 함수와 함께 사용하여 모델이 두 클래스 중 하나를 선택하는 확률을 학습하는 목적 함수
- 2번: 자동으로 학습률을 조절. 수렴이 빠르고 하이퍼파라미터 튜닝의 필요성이 적음
- 3번: 특정 지점에서 모델의 가중치를 저장하는 콜백 함수.
-  --: filepath=저장경로, monitor=관찰대상, save_best_only=이전보다 오차가 적은 모델이면 저장(T/F)



<br/><br/>
<br/><br/>

## 2. 조예림 문제
![image](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/128358741/15cfe29e-4f4e-4c89-b6e0-7bc11f907db0)

- A1: 0.2 / compile(틀렸다. fit 즉 피팅, 적합화) / matplotlib / 'loss'(틀렸다. 'val_loss' 즉 value의 loss) / 'acc'
- A2: EarlyStopping()

