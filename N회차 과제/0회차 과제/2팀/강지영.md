# 3장
## 1. 선형 회귀(linear regression): 가장 훌륭한 예측선 긋기

+ 변수 x와 y의 관계를 'x 값이 변함에 따라 y값도 변한다'라고 정의했을 때 x를 독립 변수, y를 종속 변수라 함
+ 단순 선형 회귀: 하나의 x값으로 y값을 설명
+ 다중 선형 회귀: 여러 개의 x값으로 y값을 설명

+ y = ax + b라는 일차함수에서 상수 a와 b를 찾아내는 작업을 선형 회귀라고 함

## 2. 최소 제곱법(method of least squares): 단순 선형 회귀에 적용
<img width="178" alt="스크린샷 2024-01-08 192027" src="https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/128336150/3b1ec4da-57a3-482c-9f6f-3430e998add5">
<br/>
<img width="189" alt="스크린샷 2024-01-08 192231" src="https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/128336150/200f36b1-83e5-4377-ac57-de4dc4de6bdd">


```
import numpy as np

# x 값과 y 값 
x=[2, 4, 6, 8]
y=[81, 93, 91, 97]

# x와 y의 평균값
mx = np.mean(x)
my = np.mean(y)
print ("x의 평균값:" , mx)
print("y의 평균값:" , my)

# 기울기 공식의 분모
divisor = sum([(mx - i)* * 2 for i in x])
# 기울기 공식의 분자
def top (x, mx, y, my):
    d = 0
    for i in range (len (x) ) ：
        d += ( x [i ] - mx) * ( y [i ] - my)
    return d
dividend = top(x, mx, y, my)

print ("분모:" , divisor)
print ("분자:" , dividend)

# 기울기와 y 절편 구하기
a = dividend / divisor
b = my - (mx*a)

# 출력으로 확인
print("기울기 a =", a)
print("y 절편 b =", b)
```

## 3. 평균 제곱 오차 (mean square error, MSE)

### ‘일단 그리고 조금씩 수정해 나가기’ 
+ 오차 = 예측값 - 실제값 <br/>
<img width="134" alt="image" src="https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/128336150/e885d5e5-9cc6-4d55-a6b3-0a98af5151da">
<br/>
<img width="200" alt="image" src="https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/128336150/6b9a3729-5972-4f82-8f56-34d19d398550">
<br/>-> 선형 회귀란 임의의 직선을 그어 이에 대한 평균 제 
곱 오차를 구하고, <br/>이 값을 가장 작게 만들어 주는 a와 b 값을 찾아가는 작업

```
import numpy as np

# 기울기 a와 y 절편 b
fake_a_b = [3, 76]

# x, y 의 데이터 값
data = [ [2 , 81 ], [4, 93】, [6, 91], [8, 97]]
x = [i[0] for i in data]
y = [i[1] for i in data]

# y = ax + b에 a와 b 값을 대입하여 결과를 출력하는 함수 
def predict (x) ：
    return fake_a_b [0]*x + fake_a_b[1]

# MSE 함수
def mse(y, y_hat):
return ( (y-y_hat) ** 2 ) .mean())

# MSE 함수를 각 y 값에 대입하여 최종 값을 구하는 함수 
def mse_val(y, predict_result):
    return mse(np.array(y), np.array(predict_result))

# 예측 값이 들어갈 빈 리스트 
predict_result = []

# 모든 x 값을 한 번씩 대입하여 
for i in range(len (x) ) ：
    # predict_result 리스트를 완성 
    predict_result. append(predict(x[ i ] ))
    print("공부한 시간=%.f, 실제 점수 =%.f, 예측 점수=%.fn % ( x [i ], y [i ],
    predict ( x [i] ) ) )

# 최종 MSE 출력
print("mse 최 종 값 : " + str(mse_val(predict_ result, y)))
```

# 4장
