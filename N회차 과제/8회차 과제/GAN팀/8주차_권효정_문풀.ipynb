{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 1\n",
        "난이도가 많이 쉽습니다…!!!\n",
        "\n",
        "다음은 교재의 영화 리뷰 긍/부정 판단 NLP의 코드 일부입니다.\n",
        "\n",
        "코드를 보고, 각 부분의 역할과 1 2 3의 순서를 맞춰주세요."
      ],
      "metadata": {
        "id": "aoycpRKLBAEe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3p-X_0Puz3KL"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "padded_x=sequences(x, 4)\n",
        "\"\\n패딩 결과\\n\", print(padded_x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "token=Tokenizer()\n",
        "token.fit_on_texts(docs)\n",
        "print(token.word_index)\n",
        "x=token.texts_to_sequences(docs)"
      ],
      "metadata": {
        "id": "n5cLpOo4BG4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "model=Sequential()\n",
        "model.add(Embedding(word_size, 8, input_length=4))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', oss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded_x, classes, epochs=20)"
      ],
      "metadata": {
        "id": "0qNK6KTbBJLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "답 <br>\n",
        "1. 패딩하는 역할\n",
        "2. 토큰화하는 역할\n",
        "3. 단어를 임베딩하는 역할\n",
        "<br>\n",
        "- 순서: 2 → 1 → 3"
      ],
      "metadata": {
        "id": "-GNI1bGXBOvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "kk7LLlb5Bv5F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제 2\n",
        "다음과 같은 코드에서 나올 결과를 적고, 이렇게 나오는 이유를 설명하시오."
      ],
      "metadata": {
        "id": "nvlp8sN0Bncf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "text= \"엔드 게임에서 아이언맨은 죽는다.\"\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts([text])\n",
        "x = token.texts_to_sequences([text])\n",
        "\n",
        "word_size = len(token.word_index)+1\n",
        "x = to_categorical(x, num_classes=word_size)\n",
        "\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3mgbz5MBLgF",
        "outputId": "5dda51cc-73c1-48b5-8d8c-7c1041158bdc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0. 1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0. 0.]\n",
            "  [0. 0. 0. 1. 0.]\n",
            "  [0. 0. 0. 0. 1.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰화를 통해 단어의 빈도 수를 확인한 후 원-핫 인코딩 방식을 활용하였기 때문에 다음과 같이 나온다."
      ],
      "metadata": {
        "id": "g-aq_7bLB20-"
      }
    }
  ]
}