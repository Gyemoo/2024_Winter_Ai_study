## Q - 박신영
+ 자카드 유사도 구하기(오른쪽에 노션에 정리함)
https://www.notion.so/54265e6315cc4883b0dfdd3344ec5f89?pvs=4
```
// 코사인 유사도 구하기 (문장 세트 1): 코사인 값을 이용해 유사도를 계산하며 1에 가까울수록 유사도가 높다고 볼 수 있음.
sentence = ("따뜻한 라면 을 먹고 싶어.", "맛 있는 밥 이 먹고 싶다.") # 단어 벡터화(각 유사도를 측정하기 전 두가지 예시 문자를 확인)

// TF-IDF를 통해 벡터화된 행렬로 변환해줌
from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer() // 객체 생성
tfidf_matrix = tfidf_vectorizer.fit_transform(sentence) // 문장 벡터화 진행
text = tfidf_vectorizer.get_feature_names_out() // 각 단어
idf = tfidf_vectorizer.idf_ // 각 단어의 벡터 값

from sklearn.metrics.pairwise import cosine_similarity
cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2]) // 사이킷런의 코사인 유사도
```
-> 코사인유사도1) array([[0.17077611]])
```
// 코사인 유사도 구하기 (문장 세트 2)
sentence = ("맛 있게 밥솥 으로 밥 을 짓겠다.", "맛 있는 밥 이 먹고 싶다.")

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer()

tfidf_matrix = tfidf_vectorizer.fit_transform(sentence)

text = tfidf_vectorizer.get_feature_names_out()

idf = tfidf_vectorizer.idf_

from sklearn.metrics.pairwise import cosine_similarity
cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])
```
-> 코사인유사도2) array([[0.]])

_________________________________________________________________________________________
## Q - 김태경
```
// 패딩: 서로 길이가 다른 문장들의 길이를 임의로 동일하게 맞춰주는 것
padded_x=sequences(x, 4)
"\n패딩 결과\n", print(padded_x)
```
```
// 토큰화: 단어를 나누거나 구분하는 작업
token=Tokenizer()
token.fit_on_texts(docs)
print(token.word_index)
x=token.texts_to_sequences(docs)
```
```
// 단어임베딩: 컴퓨터가 단어를 숫자로 표현하여 컴퓨터가 작업할 수 있도록 하는 방법
model=Sequential()
model.add(Embedding(word_size, 8, input_length=4))
model.add(Flatten())
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='adam', oss='binary_crossentropy', metrics=['accuracy'])
model.fit(padded_x, classes, epochs=20)
```
+ 순서: 2->1->3
