# 14장
## 1. 데이터의 확인과 실행

```
df_pre = pd.read_csv('../dataset/wine.csv', header = None)
df = df_pre.sample(frac = 1)
print(df.info())
```
+ df_pre라는 공간에 데이터를 부르고 sample()함수를 이용해 원본 데이터의 몇 %를 사용할지 지정
+ frac = 1이라고 지정하면 원본 데이터의 100%를 불러오라는 의미
```
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint, EarlyStopping

import pandas as pd
import matplotlib.pyplot as plt
import numpy
import tensorflow as tf

# seed값 설정
seed=0
numpy.random.seed(seed)
tf.random.set_seed(3)

# 데이터 입력
df_pre=pd.read_csv('wine.csv', header=None)
df=df_pre.sample(frac=1)
dataset=df.values
X=dataset[:,0:12]
Y=dataset[:,12]

# 모델 설정
model=Sequential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss='binary_crossentropy', optimizer='adam', matrics=['accuracy'])

# 모델 실행
model.fit(X, Y, epochs=200, batch_size=200)

# 결과 출력
print("\n Accuracy: %.4f" % (model.evaluate(X, Y)[1]))
```
+ 이항 분류 
(binary classification) 문제이므로 오차 함수는 binary _crossentropy를 사용
+ 최적화 함수로 adam ()을 사용
+ 정확도가 98.58%인 딥러닝 프레임워크를 완성

## 2. 모델 업데이트하기
+ 에포크(epoch)마다 모델의 정확도 기록하며 저장
+ 폴더를 확인하고 에포크 횟수와 이때의 테스트셋 오차 값을 이용해 파일 이름을 만들어 hdf5라 
는 확장자로 저장
+ 모델을 저장하기 위해 케라스의 콜백 함수 중 M odelCh eckpoin t( ) 함수 사용
+ 모 
델이 저장될 곳을 앞서 만든 m odelpath로 지정하고 v e rb o s e의 값을 1 로 정하면 
해당 함수의 진행 사항이 출력되고, 0으로 정하면 출력되지 않음
```
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint	# 모델을 저장하기 위해 케라스의 콜백 함수 중 이 함수를 불러옴

import pandas as pd
import numpy
import os
import tensorflow as tf

# seed값 설정
numpy.random.seed(3)
tf.random.set_seed(3)

# 데이터 입력
df_pre=pd.read_csv('wine.csv', header=None)
df=df_pre.sample(frac=1)
dataset=df.values
X=dataset[:,0:12]
Y=dataset[:,12]

# 모델 설정
model=Sequential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss='binary_crossentropy', optimizer='adam', matrics=['accuracy'])

# 모델 저장 폴더 설정
MODEL_DIR='./model/'	# 모델 저장하는 폴더
if not os.path.exists(MODEL_DIR): os.mkdir(MODEL_DIR)	# 만일 위의 폴더가 존재하지 않으면 이 이름의 폴더를 만들어 줌

# 모델 저장 조건 설정
modelpath="./model/{epoch:02d}-{val_loss:.4f}.hdf5"
checkpointer=ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

# 모델 실행 및 저장
model.fit(X, Y, validation_split=0.2, epoch=200, batch_size=200,
verbose=0, callbacks=[checkpointer])

```

## 3. 그래프로확인하기

```
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint

import pandas as pd
import numpy
import os
import matplotlib.pyplot as plt
import tensorflow as tf

# seed값 설정
numpy.random.seed(3)
tf.random.set_seed(3)

# 데이터 입력
df_pre=pd.read_csv('wine.csv', header=None)
df=df_pre.sample(frac=1)
dataset=df.values
X=dataset[:,0:12]
Y=dataset[:,12]

# 모델 설정
model=Sequential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss='binary_crossentropy', optimizer='adam', matrics=['accuracy'])

# 모델 저장 폴더 설정
MODEL_DIR='./model/'
if not os.path.exists(MODEL_DIR): os.mkdir(MODEL_DIR)

# 모델 저장 조건 설정
modelpath="./model/{epoch:02d}-{val_loss:.4f}.hdf5"
checkpointer=ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

# 모델 실행 및 저장
history=model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500)

# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장
y_vloss=history.history['val_loss']

# y_acc에 학습셋으로 측정한 정확도의 값을 저장
y_acc=history.history['acc']
# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시
x_len=numpy.arange(len(y_acc))
plt.plot(x_len, y_vloss, "o", c="red", markersize=3)
plt.plot(x_len, y_acc, "o", c="blue", markersize=3)

plt.show()
```
+ 모델이 학습되는 과정을 history 변수를 만들어 저장

## 4. 학습의자동중단
+ EarlyStopping( ) 함수: 테스트셋 오차가 줄지 않으면 학습을 멈추게 하는 함수
+ EarlyStopping( ) 함수에 모니터할 값과 테스트 오차가 좋아지지 않아도 몇 번 
까지 기다릴지를 정하고 early_stopping_callback에 저장

```
from keras.callbacks import EarlyStopping
```

```
early_stopping_callback = EarlyStopping(monitor='val_loss', 
patience=100)
```

```
model.fit(X, Y, validation_split=0.33, epochs=2000, batch_size=500,
callbacks=[early_stopping_callback])
```


