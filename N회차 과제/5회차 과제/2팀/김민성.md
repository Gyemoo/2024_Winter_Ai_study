## 14장
### 1. 데이터의 확인과 실행
1. sample( ) 함수는 원본 데이터에서 정해진 비율만큼 랜덤으로 뽑아오는 함수입니다. frac=1이라고 지정하면 원본 데이터의 100%를 불러오라는 의미입니다.
```python
df_pre = pd.read_csv('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=1)
```

2. 와인의 종류 예측하기
```python
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint, EarlyStopping

import pandas as pd
import numpy
import tensorflow as tf
import matplotlib.pyplot as plt

# seed 값 설정 
seed = 0
numpy.random.seed(seed)
tf.random.set_seed(3)

# 데이터 입력
df_pre = pd.read_csv ('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=1)
dataset = df.values
X = dataset[:,0:12]
Y = dataset[:,12]

# 모델 설정
model = Sequential( )
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model. compile( loss='binary_crossentropy',
                optimizer='adam',
                metrics= ['accuracy'])

# 모델 실행
model.fit(X, Y, epochs=200, batch_size=200)

# 결과 출력
print("\n Accuracy: %.4f" %(model.evaluate(X, Y)[1]))
```

```python
Epoch 00194: saving model to ./model/194-0.0629.hdf5 
Epoch 00195：saving model to ./model/195-0.0636.hdf5 
Epoch 00196：saving model to ./model/196-0.0630.hdf5 
Epoch 00197：saving model to ./model/197-0.0695.hdf5 
Epoch 00198：saving model to ./model/198—0.0724.hdf5 
Epoch 00199：saving model to ./model/199-0.0635.hdf5
```

###  2. 모델 업데이트
```python
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint

import pandas as pd
import numpy
import os
import tensorflow as plt

# seed 값 설정
numpy.random.seed(3)
tf.random.set_seed(3)

df_pre = pd.read_csv ('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=1)

dataset = df.values
X = dataset[:,0:12]
Y = dataset[:,12]

# 모델 설정
model = Seqential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss='binary_crossentropy' ， 
                optimizer:'adam'， 
                metrics=['accuracy'])

# 모델 저장 폴더 설정 
MODEL.DIR = './model/'
if not os.path.exists(MODEL_DIR):
    os.mkdir(M0DEL_DIR)

# 모델 저장 조건 설정
modelpath="./model/{epoch:02d}-{val_loss：.4f}.hdf5"
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

# 모델 실행 및 저장
model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer])
```

```python
(중략)
Epoch 00183： val_loss improved from 0.04916 to 0.04863, saving model to ./
model/183-0.0486.hdf5
Epoch 00184：val_loss did not improve
Epoch 00185：val_loss did not improve
Epoch 00186：val_loss did not improve
Epoch 00187：val_loss did not improve
Epoch 00188：val_loss did not improve
Epoch 00189：val_loss did not improve
Epoch 00190：val_loss did not improve
Epoch 00191：val_loss did not improve
Epoch 00192: val_loss did not improve
Epoch 00193: val_loss improved from 0.04863 to 0.04855, saving model to ./
model/193-0.0486.hdf5
Epoch 00194：val_loss did not improve
Epoch 00195：val_loss did not improve
Epoch 00196：val_loss did not improve
Epoch 00197：val_loss did not improve
Epoch 00198: val_loss improved from 0.04855 to 0.04823, saving model to ./
model/198-0.0482.hdf5
Epoch 00199：val_loss did not improve
```

### 3. 그래프로 확인하기
```python
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint

import pandas as pd
import numpy
import os
import tensorflow as plt

# seed 값 설정
numpy.random.seed(3)
tf.random.set_seed(3)

df_pre = pd.read_csv ('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=1)

dataset = df.values
X = dataset[:,0:12]
Y = dataset[:,12]

# 모델 설정
model = Seqential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss='binary_crossentropy' ， 
                optimizer:'adam'， 
                metrics=['accuracy'])

# 모델 저장 폴더 설정 
MODEL.DIR = './model/'
if not os.path.exists(MODEL_DIR):
    os.mkdir(M0DEL_DIR)

# 모델 저장 조건 설정
modelpath="./model/{epoch:02d}-{val_loss：.4f}.hdf5"
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

# 모델 실행 및 저장
history = model.fit(X, Y, validation_split=0.33, batch_size=500)

# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장
y_vloss=history.history['val_loss']

# y_acc에 학습셋으로 측정한 정확도의 값을 저장 
y_acc=history.history['acc']

# x값을 지정하고 정확도를 파란색으로, 오차 를 빨간색으로 표시 
x_len = numpy.arange(len(y_acc))
plt.plot(x_len, y_vloss, c="red", markersize=3)
plt.plot(x_len, y_acc, "o", c="blue", markersize=3)

plt.show()
```

```python
Epoch 3497/3500
653/653 [====================================] -0s -loss:0.0119 - acc: 0.9954 - val_loss： 0.0976 一 val_acc： 0.9783 
Epoch 3498/3500
653/653 [====================================]-0s - loss： 0.0102 - acc:0.9985 - val_loss： 0.0885 - val_acc： 0.9783 
Epoch 3499/3500
653/653 [====================================] - 0s - loss： 0.0123 一 acc：0.9954 - val_loss： 0.0933 - val_acc： 0.9783 
Epoch 3500/3500
653/653 [====================================] - 0s - loss： 0.0097 一 acc：0.9969 - v aljo ss： 0.0958 - val_acc： 0.9783
```
![image](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/128350167/1fd03f66-3475-481e-b941-1228bcb071df)


### 4. 학습의 자동 중단
```python
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint

import pandas as pd
import numpy
import os
import tensorflow as plt

# seed 값 설정
numpy.random.seed(3)
tf.random.set_seed(3)

df_pre = pd.read_csv ('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=1)

dataset = df.values
X = dataset[:,0:12]
Y = dataset[:,12]

# 모델 설정
model = Seqential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss='binary_crossentropy' ， 
                optimizer:'adam'， 
                metrics=['accuracy'])

# 학습 자동 중단 설정
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)

# 모델 실행
model.fit(X, Y, validation_split=0.2, epochs=2000, batch_size=500, callbacks=[early_stopping_callback])

# 결과 출력
print("\n Accuracy：%.4f" % (model.evaluated(X, Y)[1]))
```

```python
(중략)
Epoch 775/2000
780/780 [============================] - Os - loss： 0.0186 - acc：
0.9962 一 valjo ss: 0.0662 - val_ acc： 0.9795 
Epoch 776/2000
780/780 ============================] - 0 s - loss： 0.0193 - acc：
0.9936 - val_ loss： 0.0743 - val_ acc： 0.9795 
Epoch 777/2000
780/780 [============================] 一 0 s - loss： 0.0198 一 acc：
0.9936 一 valjo ss： 0.0660 一 val_ acc: 0.9795 
Epoch 778/2000
780/780 [============================] - 0 s - loss： 0.0236 - acc：
0.9936 - valjo ss： 0.0699 一 val_ acc： 0.9846
32/975 [................................. ] - ETA： 0 s
Accuracy: 0.9918
```
에포크는 2000으로 설정하였지만 도중에 계산이 멈추기 때문에 모델 업데이트 함수와 학습 자동 중단 함수를 동시에 사용해보면 다음과 같습니다.

#### 전체 코드

```python
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint

import pandas as pd
import numpy
import os
import tensorflow as plt

# seed 값 설정
numpy.random.seed(3)
tf.random.set_seed(3)

df_pre = pd.read_csv ('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=1)

dataset = df.values
X = dataset[:,0:12]
Y = dataset[:,12]

# 모델 설정
model = Seqential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
model.compile(loss='binary_crossentropy' ， 
                optimizer:'adam'， 
                metrics=['accuracy'])

# 모델 저장 폴더 설정 
MODEL.DIR = './model/'
if not os.path.exists(MODEL_DIR):
    os.mkdir(M0DEL_DIR)

# 모델 업데이트 및 저장
checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

# 학습 자동 중단 설정
early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)

# 모델 실행
model.fit(X, Y, validation_split=0.2, epochs=2000, batch_size=500, verbose=0, callbacks=[early_stopping_callback,checkpointer])
```







