## 14] 베스트 모델 만들기
### 데이터의 확인과 실행
#### - sample(): 원본 데이터에서 정해진 비율만큼 랜덤으로 뽑아오는 함수
```
df = df_pre.sample(frac=1) //frac=1이라고 지정하면 원본 데이터의 100%를 불러오라는 의미
```
```
#seed 값 설정
seed = 0
numpy.random.seed(seed)
tf.random.set_seed(3)

#데이터 입력
df_pre = pd.read_csv('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=1)
dataset = df.values
X = dataset[:,0:12]
Y = dataset[:,12]
```

#### - 에포크(epoch)마다 모델의 정확도를 함께 기록하면서 모델을 저장
```
import os

MODEL_DIR = './model/' //모델을 저장하는 폴더
if not os.path.exists(MODEL_DIR): //만일 위의 폴더가 존재하지 않으면
    os.mkdir(MODEL_DIR) //이 이름의 폴더를 만들어 줌

modelpath="./model/{epoch:02d}-{val_loss:.4f}.hdf5"
```

#### - ModelCheckpoint(): 모델을 저장하기 위한 케라스의 콜백 함수
```
from keras.callbacks import ModelCheckpoint

checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1) //모니터할 값을 지정

model.fit(X, Y, validation_split=0.2, epochs=200, batch_size=200, verbose=0, callbacks=[checkpointer]) //모델을 학습할 때마다 checkpointer의 값을 받아 지정된 곳에 모델을 저장
```
+ 케라스 내부에서 학습 정확도는 acc, 테스트셋 정확도는 val_acc, 학습셋 오차는 loss로 기록된다
+ verbose의 값을 1로 정하면 해당 함수의 진행 사항이 출력되고, 0으로 정하면 출력되지 않는다
  
#### 저장된 파일의 이름이 곧 에포크 수와 이때의 테스트셋 오차 값이다
+ ModelCheckpoint() 함수에 모델이 앞서 저장한 모델보다 나아졌을 경우에만 모델을 저장하게끔 하려면 save_best_only 인자를 True로 지정해주면 된다

```
#모델 실행 및 저장
history = model.fit(X, Y, validation_split=0.33, epochs=3500, batch_size=500)

#y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장
y_vloss=history.history['val_loss']

#y_acc에 학습셋으로 측정한 정확도의 값을 저장
y_acc=history.history['acc']

#x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시
x_len = numpy.arrange(len(y_acc))
plt.plot(x_len, y_vloss, "o", c="red", markersize=3)
plt.plot(x_len, y_acc, "o", c="blue", markersize=3)

plt.show()
```
+ 학습셋의 정확도는 시간이 흐를수록 좋아지는 반면에 테스트 결과는 과적합으로 인해 어느 정도 이상의 시간이 흐르게 되면 더 나아지지 않는 것을 그래프로 확인할 수 있다

#### EarlyStopping(): 학습이 진행되어도 테스트셋 오차가 줄지 않으면 학습을 멈추게 하는 케라스 콜백 함수
```
from keras.callbacks import EarlyStopping

early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100) //학습 자동 중단 설정

model.fit(X, Y, validation_split=0.33, epochs=2000, batch_size=500, callbacks=[early_stopping_callback]) //모델 실행
```

### 최종 코드
```
from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import ModelCheckpoint, EarlyStopping

import pandas as pd
import numpy
import os
import tensorflow as tf

numpy.random.seed(3)
tf.random.set_seed(3)

df_pre = pd.read_csv('../dataset/wine.csv', header=None)
df = df_pre.sample(frac=0.15) ##15%만 사용
dataset = df.values
X = dataset[:,0:12]
Y = dataset[:,12]

model = Sequential()
model.add(Dense(30, input_dim=12, activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

MODEL_DIR = './model/'
if not os.path.exists(MODEL_DIR):
  os.mkdir(MODEL_DIR)

modelpath="./model/{epoch:02d}-{val_loss:.4f}.hdf5"

checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)

early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)

model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500, verbose=0, callbacks=[early_stopping_callback, checkpointer])
```
