### Q1. 기울기 소실 문제의 대안으로 나온 함수의 이름과 해결 방법을 서술하시오.
### Q2. 그럼 위 함수의 한계는 무엇인지 생각해보고 서술하시오.
### Q3. 죽은 렐루 문제에 대한 해결책으로 나온 함수와 그 방법은?


#### Q1.HINT 
![image](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/70877858/7300acd9-43b5-47dc-bbe9-976a7680c700)


<details>
<summary>토글 접기/펼치기</summary>
<div markdown="1">

#### A1 : 렐루(ReLU)함수 : 양수는 그대로 음수는 0으로 반환하기 때문에 미분값이 1이기 때문에 기울기 소실문제가 발생하지 않고 학습효과가 계속 지속될 수 있다. 
#### A2 : 죽어가는 렐루(Dying ReLU) : 특정 출력이 0이 되면 여태까지 학습하여 곱했던 기울기 값에 0을 곱하게 됨으로써 가중치 업데이트가 안 됨
#### A3 : 2가지 방법이 있음
#### A3-1) 리키 렐루(Leaky ReLU) : 입력값이 음수일 경우에 0이 아니라 0.01과 같은 매우 작은 수를 반환하도록 하여 해결
#### A3-2): PReLU x가 양수일 땐 x 값을 그 외에는 ax값을 도출하여 해결 (여기서 a값은 다른 신경망 매개변수와 함께 학습되는 파라미터)

</div>
</details>


