# 신영이 문제

## 문제 1
다층 퍼셉트론과 오차 역전파를 이용하여 만든 신경망, 


이 신경망을 거듭하여 반복할 경우 고차원적인 사고가 가능한 


인공지능을 개발할 수 있을 것만 같은데 그러지 못한다.


그 주된 이유가 되는 문제는 무엇인가?


> 답: 기울기 소실 문제     
> 다음 문제에서 이 내용에 대한 설명을 다루므로 답만 적고 넘어갑니다.


## 문제 2
문제 1의 정답이 되는 OOO OO 문제는 시그모이드 함수의 미분값과 관련되어있다.


이는 시그모이드 함수의 OOO에 대한 편미분값인데,


시그모이드 함수의 미분 최댓값은 약 0.3으로,


은닉층을 거듭 내려갈수록 이 미분값이 계속 곱해지며


최종적으로는 OOO의 오차를 수정하는 수정값이 0에 수렴하여


오차 수정이 되지 않는 문제가 생긴다.


> 답: 가중치     
> 다층 퍼셉트론의 가중치와 바이어스를 찾아가는 과정에서 미분을 하게 되는데, 은닉층을 거듭할수록 수정값이 작아지게 됩니다.
> ![image](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/127960949/1676fae4-fe8e-4bfe-bf6b-29ef95c79f0a)
> ![image](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/127960949/26994cff-9b4f-45e8-8f29-f1c19c665039)



## 문제 3
문제 1의 정답이 되는 OOO OO 문제를 해결하는 방법은?

> 답 : 우리가 활성화 함수로 사용했던 시그모이드 함수 외에 다른 활성화 함수를 사용한다.
> ![제목 없음](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/127960949/e6a9093e-a520-441f-9421-3a513a3bb3fd)
> ![image](https://github.com/sejongsmarcle/2024_Winter_Ai_study/assets/127960949/42e809bd-f0e0-48cc-89a8-b80330f4f0df)


## 문제 4
시그모이드 함수를 대체하는 활성화 함수 중


현재 가장 많이 쓰이는 함수는 ReLU 함수이다.


시그모이드를 대체할 수 있었던, ReLU 함수의 강점은 무엇인가?(객관식)


1. 함수를 만든 사람의 명성이 높다.
2. 함수의 방정식이 간단하다.
3. x가 양의 값을 가질 때 기울기가 일정하다.
4. x가 양의 값을 가질 때 기울기가 1이다.
5. x가 음의 값을 가질 때 y값이 일정하다.


> 답: 4번 x가 양의 값을 가질 때 기울기가 1이다.
> 기울기가 1이라는 것은 여러 번 미분해도 값이 1이라는 것이고, 시그모이드 함수에서 미분을 거듭함에 따라서 값이 점점 0에 수렴하게 되는 문제를 해결할 수 있다.


# 시현이 문제

## 오차 역전파에 관한 문제입니다. 빈칸에 들어갈 알맞은 말을 찾으세요.
1. MSE에서 우린 임의의 직선을 그리고 오차를 구한 뒤 경사 하강법을 이용하여 오차를 수정해가며 최적의 a와 b값을 찾았다(단일 퍼셉트론인 경우). 
이와 유사하게, 신경망(== 다층 퍼셉트론) 내부의 가중치는 오차 역전파를 이용하여 수정한다.</br>
2. 또한, XOR 문제를 해결하기 위해 앞서 사용한 다층 퍼셉트론의 논리 연산에선 가중치와 바이어스의 값이 주어졌다. 그런데 실제 문제에선 우리가 직접 구해야 하는데, 이때 사용하는 것이 오차 역전파이다.
