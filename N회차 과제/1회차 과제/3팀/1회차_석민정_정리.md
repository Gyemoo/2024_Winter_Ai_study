## 5장 참 거짓 판단 장치: 로지스틱 회귀
: 딥러닝을 수행한다는 것은 복잡한 연산을 해낸 끝에 최적의 예측 값을 내놓는 작업이라고 할 수 있음.
+ 로지스틱 회귀의 원리를 이용해 주어진 입력 값의 특징 추출하고 이를 저장하여 모델을 만드는 것이 딥러닝의 동작 원리임.
+ 로지스틱 회귀: 참과 거짓 사이를 구분하는 S자 형태의 적절한 선을 그려나가는 과정
+ a는 그래프의 경사도를 결정하고, b는 그래프의 좌우 이동을 의미함.
+ 경사하강법: 먼저 오차를 구한 다음 오차가 작은 쪽으로 이동시키는 방법

시그모이드 함수의 특징| y값이 0과 1 사이임 -> log함수 함께 사용해야함.

로그 함수에서 파란색 선은 -logh, 실제 값이 1일 때 사용할 수 있는 그래프이고, 빨간색 선은 -log(1-h),  실제 값이 0일 때 사용할 수 있는 함수임.
```
def sigmoid(x): #sigmoid 함수 정의
return 1/(1+np.e ** (-x))
```

```
for i in range(2001): #경사 하강법 실행
    for x_data, y_data in data:
        a_diff = x_data*(sigmoid(a*x_data+b)-y_data)
        b_diff = sigmoid(a*x_data+b)-y_data
        a = a-lr*a_diff
        b = b - lr*b_diff
        if i % 1000 == 0:
            printf("epoch=%.f, 기울기=%.04f, 절편=%0.4f", %(i,a,b))
```

```
plt.scatter(x_data,y_data) #기울기와 절편을 이용해 그래프 그리기
plt.xlim(0,15)
plt.ylim(0,15)
x_range=(np.arrange(0,15,0.1)) #그래프로 나타낼 x 값의 범위 정하기
plt.plot(np.arrange(0,15,0.1), np.array([sigmoid(a*x+b) for x in x_range]))
plt.show()
```
___________________________________________________
## 6장 퍼셉트론
: 인간의 뇌 속 뉴런의 메커니즘은 로지스틱 회귀와 많이 닮아있음.
+ 신경망의 기본 구조: 여러 층의 퍼셉트론을 서로 연결시키고 복잡하게 조합하여 주어진 입력 값에 대한 판단을 하게 하는 것임.
+ 여기서 퍼셉트론은 신경망을 이루는 가장 중요하고 작은 신경망 기본 단위를 뜻함.
+ ' y = wx + b' 에서 w 는 가중치이고, b는 바이어스임.
+ 가중합: 입력값과 가중치의 곱을 모두 합한 다음 바이어스를 더한 값.
+ 활성화 함수: 가중합의 결과가 0과 1인 것을 판단하는 함수. (ex. 시그모이드 함수)

XOR 문제(논리 회로)]
+ 게이트: 0과 1 두 가지의 디지털 값을 입력해 하나의 값을 출력하는 회로.
+ AND 게이트: x1, x2 둘 다 1일 때 결괏값이 1로 출력하며 직선을 그어 결괏값이 1인 값을 구별 가능함.
+ OR 게이트: x1, x2 둘 중 하나라도 1이면 결괏값이 1로 출력하며 직선을 그어 결괏값이 1인 값을 구별 가능함.
+ XOR 게이트: x1, x2 둘 중 하나만 1일 때 결괏값이 1로 출력하며 직선을 그어 구분할 수 없음.
+ 결괏값이 0이면 흰점, 결괏값이 1이면 검은점으로 나타내어 그래프를 그림.
+ 다층 퍼셉트론이 등장하면서 문제가 해결될 수 있었음.
