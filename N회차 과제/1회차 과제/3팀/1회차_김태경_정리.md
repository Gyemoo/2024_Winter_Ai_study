로지스틱 회귀, 퍼셉트론
================
로지스틱 회귀
======================
로지스틱 회귀 : 선형 회귀와는 반대로 O / X로 답을 내놓아야 하는 문제에 대해 사용가능한 방법으로, 이 O와X를 가려내는 S자형 선을 찾아내는 방법이다.
이 때 사용되는 것이 바로 시그모이드함수로, y=1/1+e^-(ax+b) 형태이다.

시그모이드 함수 : 로지스틱 회귀에 사용되는 그 S자꼴로 그래프가 나오는 함수. 기본형은 y=1/1+e^-(ax+b)로, 여기서 a는 s자의 경사도, b는 그래프의 좌우 이동을 의미한다.
이 두 요인에 의해 오차가 변한다. 특히나 a는, 작아질수록 오차가 커진다. 물론 커진다고 오차가 없어진다는 보장은 없지만.

로지스틱 회귀에는 실제 값이 1일때와 0일때가 갈리기 때문에, 이를 위해 로그함수를 동시에 사용한다.

이렇게 로지스틱 회귀를 구현한다면, 주로 각 단계의 노드들에서 1 또는 0의 결과를 다음 노드로 전달해줘야 하는 퍼셉트론 방식에 주로 사용된다.

퍼셉트론
====================
퍼셉트론 : 가장 기초적인 단계의 딥러닝 알고리즘. 인간의 신경망을 모방하여 만들어졌으며, 인간의 뉴런처럼 다수의 노드가 입력층/은닉층/출력층을 이루어 연산을 진행한다.
각각의 노드에서는 시그모이드함수를 이용해 연산을 진행하며, 이때 a를 가중치, b를 바이어스라고 부른다. 그리고 ax+b의 경우, 가중합이라고 부른다.
참고로 시그모이드 함수 이외의 다른 활성화 함수들도 사용 가능한데, 현재 우리가 학습하는 단계에서는 주로 시그모이드를 활용한다.

퍼셉트론을 사용하면 and 연산과 or연산은 간단히 가능한데, 선 하나로 ox가 쉽게 나오지 않는 xor 연산 같은 경우는 은닉층을 1개 이상 사용한 다층 퍼셉트론을 사용해야만 한다.
