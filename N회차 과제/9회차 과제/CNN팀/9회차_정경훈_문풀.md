## 문제1 
input_shape: (batch_size, 100, 30)이고,

```python
model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv1D(64, 3, activation='relu', input_shape=(100, 30)))
model.add(tf.keras.layers.MaxPool1D(2))
```

위 코드에서 Conv1D 레이어를 통과한 후 출력 차원은 **(batch_size, 98, 64)이다.**

MaxPool1D 레이어를 통과한 후의 출력 차원은 얼마인가?

### 답 1


pool_size: int, size of the max pooling window.
가 2이므로 
(batch_size, 98/2, 64)=> (batch_size, 49, 64)

## 문제 2
RNN은 (1)의 약자로, 뉴런의 출력이 다시 입력으로 피드백되는 재귀적인 연결 구조를 갖는 신경망이다.
다층 퍼셉트론 신경망은 입력이 출력 방향으로만 활성화되고 은닉 뉴런이 과거의 정보를 기억하지 못한다는 단점이 있다.
이러면 입력이 들어온 문맥을 기억할 수 없고, 이런 단점은 (2) 관련 문제에서 매우 해롭다.

그래서 RNN은 앞에서 무슨 단어가 나왔는지의 문맥이 다음에 나올 단어를 예측하는 문제를 푸는 데 유용하다.
이런 문제에는 (3), (4), (5)이 있다.

그러나 해당 문제들을 전통적인 RNN으로 풀 때 문제가 있는데,
가장 처음에 학습한 문제는 점점 1보다 작은 값이 여러번 곱해져 결국 잊혀지게 된다는 것이다. 이를 (6)이라 하고, 해당 문제를 개선한 RNN의 개선판 알고리즘을 (7)이라 한다.

### 답 2
- Recurrent Neural Network
- 시계열 분석
- 필기체 인식
- 음성 인식
- 텍스처 인식
- gradient vanishing
- Long Short Term Memory(LSTM)
