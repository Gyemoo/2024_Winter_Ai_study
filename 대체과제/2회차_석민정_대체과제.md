<10줄 정리>
1) 로지스틱 회귀는 참과 거짓 사이를 구분하는 S자 형태의 선을 그려가는 과정이다.
2) 시그모이드 함수에서 x가 음의 무한대로 가면 0으로 수렴하게 되고, x가 양의 무한대로 가면 1로 수렴하게 된다.
3) 시그모이드 함수의 a 값이 커지면 경사도가 커지고, a 값이 작아지면 경사가 작아진다. 시그모이드 함수의 b 값이 커지면 왼쪽으로, b 값이 작아지면 오른쪽으로 그래프가 이동하며 이차함수 형태의 오차 그래프가 나온다.
4) a, b 값은 경사 하강법을 이용해 구하며 오차는 예측 값에서 실제 값을 뺀 값으로 실제 값이 1에 가까울 때 예측값이 0에 가까우면 오차가 커지는 것이고 로그함수 형태를 띄게 된다.
5) 두 그래프를 동시에 사용하기 위해선 -{y_data logh + (1 - y_data) log(1-h)} 공식을 사용한다.
6) a에 관한 편미분 공식 => x_data*(sigmoid(a*x_data+b)-y_data), b에 관한 편미분 공식 => sigmoid(a*x_data+b)-y_data이다.
7) 퍼셉트론은 인간 뇌의 뉴런과 비슷하며, 입력 값과 활성화 함수를 사용해 출력 값을다음으로 넘기는 가장 작은 신경망 단위이다.
8) y = wx + b (w는 가중치, b는 바이어스), 가중합은 입력값 x와 가중치의 곱을 모두 더하고 바이어스를 더한 값을 뜻하며, 활성화 함수는 0과 1을 판단하게 된다.
9) 퍼셉트론은 선을 긋는 작업이지만, 입력 값에 따라 아무리 그어도 해결되지 않는 상황이 생길 수 있다.
10) XOR(exclusive OR)은 두 입력 중 하나의 값만 1이어야 1이 출력되며 참과 거짓을 선을 그어 구분할 수 없게 된다.
